下面给你一份可落地的技术方案，围绕“**仅用 Redis 做计数、不落库兜底**、**异步聚合写**、**高效判重**、**RDB+AOF+周期校正**”这四条要求展开。方案包含数据结构与模块设计、消息流&聚合器、判重数据结构、持久化与异步校正、以及可直接复用的关键命令、Lua 脚本与伪代码。

---

# 一、计数模型与存储（CountInt）

## 1.1 目标与约束

* **所有计数（阅读/点赞/收藏/评论/转发）只在 Redis**，不落数据库兜底。
* **5 字节整型（Int5）数组**组成的**固定长度**计数对象，作为**Redis 新对象类型**：`CountInt`。
* `CountInt` 对象**总字节数永远是 5 的整数倍**；每个 Int5 对应的**业务含义不写入对象本身**，由**计数元数据中心**（单独的 Schema）映射。
* 计数对象要求：**O(1)单指标读写**、**原子多指标自增**、**可批量聚合自增**、**对热 Key 友好（支持流水线/Lua/模块原子操作）**。

> 注：实现新对象类型推荐用 **Redis Module（C 语言 + Redis Modules API）**。若阶段一先行，可用 **String + 固定偏移二进制布局** 作为临时实现，命令通过 **Lua** 保证原子性，后续切到模块时命令名不变。

## 1.2 CountInt 内存布局（Module 版与临时版一致）

* Key 形式：`cnt:{schema}:{etype}:{eid}`，例如 `cnt:v1:note:123456`
* Value 布局：`[c0(5B) | c1(5B) | ... | cN(5B)]`，**小端**或**大端**二选一（统一规定）。
* 计数范围：`0 ~ (2^40 - 1)`（约 1.1 万亿）足够大多数场景。
* 支持命令（模块提供）：

  * `CINT.GET key idx`：读取第 idx 项（0-based）
  * `CINT.MGET key idx1 idx2 ...`
  * `CINT.INCRBY key idx delta`：对 idx 自增 delta（允许负数做回滚）
  * `CINT.BATCHINCR key idx1 delta1 idx2 delta2 ...`：**多指标一次原子更新**
  * `CINT.INIT key len`：初始化为 `len` 个 Int5（全部 0）
  * `CINT.LEN key`：返回 Int5 个数
  * `CINT.DUMP key`：调试导出十进制数组
* RDB/AOF：模块需实现 `rdb_save`/`rdb_load`、`aof_rewrite` 回调，保证完整持久化。

> **临时实现（无模块时）**：用 `SET` 二进制串 + `EVALSHA` Lua 基于 `GETRANGE/SETRANGE` + 位操作读写 5 字节字段（或在 Lua 内用 `string.pack/unpack`），对外暴露相同语义的包装命令。

## 1.3 计数 Schema（计数元数据中心）

* 用于**定义每个 Int5 的含义和顺序**，避免对象里存元信息。
* Key：`schema:{schema_id}` 使用 Hash：

  * `len` → `5`（示例）
  * `0` → `read`
  * `1` → `like`
  * `2` → `fav`
  * `3` → `comment`
  * `4` → `repost`
* 反向索引（指标名到下标）：`schema:{schema_id}:idx_by_name`（Hash）

  * `read`→`0`，`like`→`1`，...
* 业务使用：**只要 Schema 不变，CountInt 不需要迁移**；如要扩展指标，可以创建 `schema:v2` 并做**灰度迁移**。

---

# 二、异步写入与“聚合写”流水线

## 2.1 消息流（推荐 RocketMQ/Kafka）

* Topic：`cnt-update`，消息结构（JSON）：

  ```json
  {
    "schema":"v1",
    "etype":"note",
    "eid":"123456",
    "metric":"like",
    "delta":1,
    "uid":"9988",
    "traceId":"...", 
    "ts": 1731312345000
  }
  ```
* **幂等保障**：消息唯一键 `dedupKey = {etype}:{eid}:{metric}:{uid}:{ts/或窗口序号}`，生产端/消费端均可做一次性去重（见 2.4）。

## 2.2 消费者批处理与“同 Key 聚合”

* 消费者每批 `N` 条（如 1000），在内存构建**两级聚合 Map**：

  * 维度一：`key = cnt:{schema}:{etype}:{eid}`
  * 维度二：指标下标 `idx`（由 Schema Hash 查询获得）
  * 值：`sumDelta`（把同一个 Key+指标的多条消息合并）
* 聚合完成后，对每个 Key 生成**一条批量原子更新**：

  * 模块命令：`CINT.BATCHINCR key idx1 d1 idx2 d2 ...`
  * 临时版：`EVALSHA` Lua 对多个 idx 做原子自增
* 使用 **Lettuce/Jedis Pipeline** 或 **MULTI/EXEC**（更推荐：**单条 Lua/模块命令**原子完成，无需事务）

### 2.3 消费端伪代码（Java）

```java
// batch = poll(N)
Map<String, Map<Integer, Long>> agg = new HashMap<>();
for (Msg m : batch) {
  String key = "cnt:" + m.schema + ":" + m.etype + ":" + m.eid;
  int idx = schemaIdxByName(m.schema, m.metric); // HGET schema:{schema}:idx_by_name {metric}
  agg.computeIfAbsent(key, k -> new HashMap<>())
     .merge(idx, m.delta, Long::sum);
}
// 聚合写
for (var entry : agg.entrySet()) {
  String key = entry.getKey();
  Map<Integer, Long> deltas = entry.getValue();
  // 调用 CINT.BATCHINCR key idx1 d1 idx2 d2 ...
  cintBatchIncr(key, deltas);
}
// ACK
```

### 2.4 幂等/去重策略

* **生产端**：对用户行为生成 `dedupKey`，先 `SETNX act:dedup:{dedupKey} 1 EX 2d` 成功再发消息；失败则丢弃（说明重复点击）。
* **消费端兜底**：若生产端不可靠，则消费者收到消息先 `SETNX` 同样的 `dedupKey` 再处理；失败则跳过。
* **重复取消**（如点赞取消）：发送 `delta = -1`，仍使用幂等键（可附加动作类型）。

---

# 三、用户是否已点赞/收藏的高效判定

> 判定“是否已操作”是**强一致需求**（不可误判）；因此建议**“精确结构 +（可选）概率结构预过滤”**的两层设计：

## 3.1 精确结构（推荐）

### 方案 A：**位图（Bitmap）**（用户 ID 上限明确且稠密）

* Key：`bm:like:{etype}:{eid}`，`SETBIT key {uid} 1`；取消 `SETBIT 0`
* 查询：`GETBIT key {uid}` O(1)
* 优点：极致省内存（每用户 1 bit），查询极快；
  缺点：要求 UID 不过大且分布相对稠密（例如 UID < 200M），否则稀疏浪费。

### 方案 B：**分片位图/稀疏位图（Roaring Bitmap 模块）**

* Key：`rbm:like:{etype}:{eid}` 使用 RoaringBitmap（如 RedisRoaring/RedisBloom-Roaring）
* 查询：`RBM.CONTAINS key uid`，新增：`RBM.ADD key uid`
* 优点：对大范围稀疏 UID 友好，空间随元素数增长；查询近 O(1)。

### 方案 C：**Set 精确集合**（通用兜底）

* Key：`s:like:{etype}:{eid}:{yyyymmdd}`（**按日切片**避免超大集合）
* 查询：当天命中直接 `SISMEMBER`；跨天可查近 N 日或用二级索引（见 4.2）。
* 优点：完全精确，天然去重；
  缺点：空间相对位图更大、`SISMEMBER` O(1) 但不如位图紧凑。

> **建议优先**：若 UID 空间受控，用 **位图/稀疏位图**；否则用**按日 Set**。
> 备注：**收藏**与**点赞**分别维护独立集合或位图。

## 3.2 概率预过滤（可选）

* 使用 **Cuckoo Filter（RedisBloom）**：`CF.ADD/EXISTS`
* 流程：先 `CF.EXISTS`，若不存在则**直接判未操作**；若存在再用**精确结构确认**，以减少高 QPS 下的精确查询比例。
* 误判率可调（如 0.1%），但**不会漏判**（先加再查）。

---

# 四、持久化与“异步校正兜底”

## 4.1 Redis 持久化与参数

* **RDB**：`save 900 1` / `save 300 10`（示例），保障冷备恢复速度
* **AOF**：`appendonly yes`，`appendfsync everysec`；开启 **AOF 重写**：`auto-aof-rewrite-percentage 100`，`auto-aof-rewrite-min-size 512mb`
* **Lazy-free**：`lazyfree-lazy-eviction yes`，减小阻塞
* **内存上限**：`maxmemory` + `volatile-lru/lfu` 策略（计数不应被驱逐，计数与索引 key 建议 `volatile-ttl` 适度或 `noeviction`，根据集群内存规划）

## 4.2 行数基准与二级索引

“**用与计数相关的数据记录总行数来修正**”——我们在 Redis 内维护**真实行为记录的“行数视图”**，周期性与 `CountInt` 做对账：

* **对点赞/收藏（去重语义）**：

  * 精确集合/位图是“**逐条行为真相源**”。
  * 生成**二级日聚合**：`h:agg:like:{etype}:{eid}`（Hash）

    * 字段：`yyyymmdd` → `count`（`SCARD` 或 `BITCOUNT` 或 `RBM.CARD`）
* **对阅读/转发（允许重复）**：

  * 维护 **Redis Stream**（或 ZINCRBY 计数器）作为**行为流水**：

    * Key：`x:read:{etype}:{eid}:{yyyymmdd}`，`XADD` 每次阅读一条（可设 `MAXLEN ~` 控制长度）
  * 日聚合：`h:agg:read:{etype}:{eid}` 的 `yyyymmdd` → `XLEN`（或滚动计数）

> **对账任务（异步）**：

* 周期（如每 5/10 分钟），并发扫描本地热点/抽样所有 Key：

  1. 读取 `CountInt` 当前值（例如 like=10003）
  2. 计算“行数基准”：近 7/30 天 `SCARD/XLEN/…` 求和 + 累加历史归档数（见下一条）
  3. 若差异 |Δ| 超阈值（如 > 0.1% 或 > 100），执行**修正**：`CINT.INCRBY key like_idx Δ`（并写一条审计日志）

* **归档策略**：为控制集合/流规模，按天**固化日聚合**到 `h:agg:*` 后，老数据的集合/流可 `DEL` 或 `EXPIRE`，同时维护 `h:agg:*:history` 的总计字段（如 `total_before_2025-11-01`）。对账时用 `历史总计 + 近 N 天聚合`。

---

# 五、读写接口与关键命令

## 5.1 读接口（HTTP/RPC）

* `GET /counter/{etype}/{eid}?metrics=read,like,fav,comment,repost`

  * 服务端使用：`CINT.MGET` 映射指标名 → idx
* `GET /status/{etype}/{eid}?uid=...`（是否已点赞/收藏）

  * 位图：`GETBIT`；Roaring：`RBM.CONTAINS`；Set：`SISMEMBER`（按日或滚动窗口）

## 5.2 写接口（异步）

* `POST /action/like`：参数 `{etype,eid,uid,op}`（op=add/remove）

  * 生产端：先 `SETNX act:dedup:... EX 2d` 成功后 **发送 MQ**（`delta = +1/-1`）
* 消费端：**批量聚合** → `CINT.BATCHINCR`；同时**更新判重结构**（位图/Set/roaring）与**流水**（Stream，可选）

## 5.3 Lua（临时无模块时的原子多指标自增）

> 将多个 5 字节字段按固定偏移增量写回：
> 伪代码思路（真实实现需用 `bit`/`string` 操作处理 40 位整数）：

```lua
-- KEYS[1] = key
-- ARGV = idx1,delta1, idx2,delta2, ...
-- 5B field size
local F=5
local key=KEYS[1]
local v=redis.call('GET', key)
if not v then
  -- 初始化长度按 schema 长度（外层先拿到len传入）
  local len = tonumber(ARGV[1]); -- 额外传入
  v = string.rep(string.char(0), len * F)
end
local startArg = 2 -- 若前置传了 len
for i=startArg,#ARGV,2 do
  local idx = tonumber(ARGV[i])
  local delta = tonumber(ARGV[i+1])
  local off = idx * F
  local seg = string.sub(v, off+1, off+F)
  local n = bytes5_to_uint(seg)       -- 自定义函数
  n = n + delta
  if n < 0 then n = 0 end
  seg = uint_to_bytes5(n)
  v = string.sub(v,1,off) .. seg .. string.sub(v,off+F+1)
end
redis.call('SET', key, v)
return 1
```

> 实际代码中需要实现 `bytes5_to_uint/uint_to_bytes5`，或把 Int5 改为 **8 字节 Int64**（实现更简单，空间增至 8B/计数）。

---

# 六、容量与性能估算（示例）

* 假设一个 `CountInt` 有 5 个指标：**5 × 5B = 25B/对象**；
  1000 万内容对象约 250MB（不含元数据、key 开销，按 Redis 实际会更多，粗略 *3~5 倍* 预估）。
* 点赞判重（位图）：

  * 若活跃 UID 2 亿、单内容有 1 万点赞，**位图**对每内容理论最大 25MB（2e8 bit），不可行。
  * 所以：

    * **热门内容**：Roaring Bitmap（压缩后按实际点赞数近似成百 KB）
    * **长尾**：按日 Set + 过期 + 日聚合
* 写放大控制：批量聚合后**每 Key 每批一次写**，比逐条 `INCR` 降两个数量级的 QPS。

---

# 七、热键与扩展

* **热键**：对超热内容，消费者聚合窗口可**缩短**，并开启 **客户端侧限流**；可对热键使用**分片 Key**（如 `cnt:v1:note:123456:{shard}`）+ 最终合并读（Lua/MGET 汇总），仅在极端热点启用。
* **多机房一致性**：使用 Redis Cluster + 同城双机房，或上层采用**单写多读**策略；跨地域使用异步复制 + 校正任务。
* **指标扩展**：新增指标仅需创建新 Schema（例如 `v2`），双写迁移后切读。

---

# 八、运维与监控

* 监控项：

  * `CountInt` 命令 QPS/时延，Lua 命中率，AOF 大小、重写频率，RDB 用时
  * 消费堆积、聚合后每批写入条数
  * 对账任务差异分布（Δ 值直方图）
* 告警：

  * AOF rewrite 失败、RDB 失败
  * 对账差异超过阈值/连续 N 次不收敛
* 审计：

  * 对账修正写入必须**记录审计日志**（如 `x:audit:cntfix` Stream）

---

# 九、端到端流程（以点赞为例）

1. 用户点击“点赞”：

   * 网关校验会话 → 写接口 `POST /action/like`
   * 生产端 `SETNX act:dedup:{eid}:{uid}:{win} EX 2d` → 成功 → 发送 MQ（`delta=+1`）

2. 消费者批读 `N=1000`：

   * 根据 `schema` 查 idx → **同 Key/同 idx 聚合**
   * 一键调用 `CINT.BATCHINCR key idx1 d1 idx2 d2 ...`
   * 更新判重结构（位图/roaring/Set），并（可选）写 Stream 流水

3. 详情页读取：

   * `CINT.MGET cnt:{schema}:{etype}:{eid} idx_like idx_fav ...`
   * `GETBIT/RBM.CONTAINS/SISMEMBER` 判定是否已点赞/收藏

4. 异步校正（每 10 分钟）：

   * 统计近 30 天 `SCARD/XLEN` + 历史累积
   * 与 `CountInt` 对比，偏差超阈值写修正，并记审计

---

# 十、落地建议与里程碑

* **里程碑 A（1~2 周）**：

  * 先用 **String + Lua** 版本实现 `CountInt`，完成读写接口、聚合消费者、位图/Set 判重、RDB+AOF、对账任务（按日 Set/Stream + 聚合 Hash）。
* **里程碑 B（2~4 周）**：

  * 开发 **Redis Module：CountInt**，提供 `CINT.*` 命令与 RDB/AOF 持久化回调，替换 Lua。
  * 引入 **Roaring Bitmap 模块** 给热门内容降本增效。
* **里程碑 C**：

  * 热键治理、二级索引压缩、跨机房策略、审计面板完善。

---

# 附：关键 Key 设计总览

* **计数对象**：`cnt:{schema}:{etype}:{eid}` → CountInt（或 String 二进制）
* **Schema 元信息**：

  * `schema:{schema}`（Hash）→ `len`,`0`→name, ...
  * `schema:{schema}:idx_by_name`（Hash）→ name→idx
* **判重结构**（三选一/混用）：

  * 位图：`bm:{metric}:{etype}:{eid}`
  * Roaring：`rbm:{metric}:{etype}:{eid}`
  * Set（日切片）：`s:{metric}:{etype}:{eid}:{yyyymmdd}`
* **行为流水**（可选）：`x:{metric}:{etype}:{eid}:{yyyymmdd}`
* **日聚合**：`h:agg:{metric}:{etype}:{eid}`（Hash: yyyymmdd→count）
* **幂等键**：`act:dedup:{etype}:{eid}:{metric}:{uid}:{win}`

---

如果你愿意，我可以把**Lua 版 `CINT.BATCHINCR` 的可运行脚本**和**Java（Lettuce）聚合消费者代码骨架**也一起给你，直接拷过去就能跑。
